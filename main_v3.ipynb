{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "from tqdm import tqdm\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Lecture des fichiers MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_uint32(b):\n",
    "    return (b[0] << 24) | (b[1] << 16) | (b[2] << 8) | b[3]\n",
    "\n",
    "def read_labels(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        _ = f.read(4)  # magic number\n",
    "        n = make_uint32(f.read(4))\n",
    "        data = np.frombuffer(f.read(n), dtype=np.uint8)\n",
    "    return data\n",
    "\n",
    "def read_images(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        _ = f.read(4)  # magic number\n",
    "        n = make_uint32(f.read(4))\n",
    "        rows = make_uint32(f.read(4))\n",
    "        cols = make_uint32(f.read(4))\n",
    "        data = np.frombuffer(f.read(n * rows * cols), dtype=np.uint8)\n",
    "        data = data.reshape(n, rows * cols)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Kernels GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit(device=True)\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + math.exp(-x))\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def dsigmoid(x):\n",
    "    s = sigmoid(x)\n",
    "    return s * (1.0 - s)\n",
    "\n",
    "@cuda.jit\n",
    "def forward_layer_kernel(W, a_in, bias, z_out, a_out):\n",
    "    i, j = cuda.grid(2)\n",
    "    if i < W.shape[0] and j < a_in.shape[1]:\n",
    "        s = 0.0\n",
    "        for k in range(W.shape[1]):\n",
    "            s += W[i, k] * a_in[k, j]\n",
    "        s += bias[i, 0]  \n",
    "        z_out[i, j] = s\n",
    "        a_out[i, j] = sigmoid(s)\n",
    "\n",
    "@cuda.jit\n",
    "def output_backward_kernel(a, Y, delta):\n",
    "    i, j = cuda.grid(2)\n",
    "    if i < a.shape[0] and j < a.shape[1]:\n",
    "        delta[i, j] = (a[i, j] - Y[i, j]) * (a[i, j] * (1.0 - a[i, j]))\n",
    "\n",
    "@cuda.jit\n",
    "def hidden_backward_kernel(W_next, delta_next, z, delta):\n",
    "    i, j = cuda.grid(2)\n",
    "    if i < z.shape[0] and j < z.shape[1]:\n",
    "        s = 0.0\n",
    "        for k in range(W_next.shape[0]):\n",
    "            s += W_next[k, i] * delta_next[k, j]\n",
    "        delta[i, j] = s * dsigmoid(z[i, j])\n",
    "\n",
    "@cuda.jit\n",
    "def update_weights_kernel(W, delta, a_prev, learning_rate, minibatch):\n",
    "    i, j = cuda.grid(2)\n",
    "    if i < W.shape[0] and j < W.shape[1]:\n",
    "        grad = 0.0\n",
    "        for k in range(delta.shape[1]):\n",
    "            grad += delta[i, k] * a_prev[j, k]\n",
    "        W[i, j] -= learning_rate / minibatch * grad\n",
    "\n",
    "@cuda.jit\n",
    "def update_biases_kernel(bias, delta, learning_rate, minibatch):\n",
    "    i = cuda.grid(1)\n",
    "    if i < bias.shape[0]:\n",
    "        s = 0.0\n",
    "        for k in range(delta.shape[1]):\n",
    "            s += delta[i, k]\n",
    "        bias[i, 0] -= learning_rate / minibatch * s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Réseau de Neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_2d(shape, block=(16, 16)):\n",
    "    gx = (shape[0] + block[0] - 1) // block[0]\n",
    "    gy = (shape[1] + block[1] - 1) // block[1]\n",
    "    return (gx, gy)\n",
    "\n",
    "def grid_1d(n, block=256):\n",
    "    return ((n + block - 1) // block,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerGPU:\n",
    "    def __init__(self, n_in, n_out, minibatch):\n",
    "        W_host = np.random.normal(0, 1/np.sqrt(n_in), (n_out, n_in)).astype(np.float64)\n",
    "        self.W = cuda.to_device(W_host)\n",
    "        self.b = cuda.to_device(np.zeros((n_out, 1), dtype=np.float64))\n",
    "        self.z = cuda.device_array((n_out, minibatch), dtype=np.float64)\n",
    "        self.a = cuda.device_array((n_out, minibatch), dtype=np.float64)\n",
    "        self.delta = cuda.device_array((n_out, minibatch), dtype=np.float64)\n",
    "\n",
    "class ANN:\n",
    "    def __init__(self, layer_sizes, alpha, minibatch):\n",
    "        self.alpha = alpha\n",
    "        self.minibatch = minibatch\n",
    "        self.n_layers = len(layer_sizes)\n",
    "        self.layers = []\n",
    "        for i in range(self.n_layers - 1):\n",
    "            n_in = layer_sizes[i]\n",
    "            n_out = layer_sizes[i+1]\n",
    "            self.layers.append(LayerGPU(n_in, n_out, minibatch))\n",
    "\n",
    "    def forward(self, X):\n",
    "        a_in = cuda.to_device(X)\n",
    "        block = (16, 16)\n",
    "        for layer in self.layers:\n",
    "            grid = grid_2d(layer.z.shape, block)\n",
    "            forward_layer_kernel[grid, block](layer.W, a_in, layer.b, layer.z, layer.a)\n",
    "            a_in = layer.a \n",
    "        out = a_in.copy_to_host()\n",
    "        return out\n",
    "\n",
    "    def backward(self, X, Y):\n",
    "        block = (16, 16)\n",
    "        output_layer = self.layers[-1]\n",
    "        Y_dev = cuda.to_device(Y)\n",
    "        grid = grid_2d(output_layer.a.shape, block)\n",
    "        output_backward_kernel[grid, block](output_layer.a, Y_dev, output_layer.delta)\n",
    "        \n",
    "        for l in range(len(self.layers) - 2, -1, -1):\n",
    "            current_layer = self.layers[l]\n",
    "            next_layer = self.layers[l+1]\n",
    "            grid = grid_2d(current_layer.a.shape, block)\n",
    "            hidden_backward_kernel[grid, block](next_layer.W, next_layer.delta, current_layer.z, current_layer.delta)\n",
    "        \n",
    "        a_prev = cuda.to_device(X)  \n",
    "        for layer in self.layers:\n",
    "            grid_w = grid_2d(layer.W.shape, block)\n",
    "            update_weights_kernel[grid_w, block](layer.W, layer.delta, a_prev, self.alpha, self.minibatch)\n",
    "            grid_b = grid_1d(layer.b.shape[0], block=256)\n",
    "            update_biases_kernel[grid_b, 256](layer.b, layer.delta, self.alpha, self.minibatch)\n",
    "            a_prev = layer.a\n",
    "\n",
    "    def predict(self, X):\n",
    "        out = self.forward(X)\n",
    "        return np.argmax(out, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Fonctions d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(labels, n_classes=10):\n",
    "    arr = np.zeros((n_classes, len(labels)), dtype=np.float64)\n",
    "    arr[labels, np.arange(len(labels))] = 1.0\n",
    "    return arr\n",
    "\n",
    "def cross_entropy_cpu(predictions, targets):\n",
    "    eps = 1e-12\n",
    "    clipped = np.clip(predictions, eps, 1 - eps)\n",
    "    return -np.sum(targets * np.log(clipped)) / predictions.shape[1]\n",
    "\n",
    "def accuracy(model, X, labels):\n",
    "    batch_size = model.minibatch\n",
    "    num_samples = X.shape[1]\n",
    "    correct = 0\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        x_batch = X[:, i:i+batch_size]\n",
    "        preds = model.predict(x_batch)\n",
    "        correct += np.sum(preds == labels[i:i+batch_size])\n",
    "    return correct / num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sacha\\miniconda3\\envs\\ECN_GPU\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "Epoch 1 - Acc: 11.31%:   0%|          | 0/3750 [00:00<?, ?it/s]c:\\Users\\sacha\\miniconda3\\envs\\ECN_GPU\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "c:\\Users\\sacha\\miniconda3\\envs\\ECN_GPU\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "c:\\Users\\sacha\\miniconda3\\envs\\ECN_GPU\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 98 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "c:\\Users\\sacha\\miniconda3\\envs\\ECN_GPU\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "c:\\Users\\sacha\\miniconda3\\envs\\ECN_GPU\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "Epoch 1 - Acc: 11.31%: 100%|██████████| 3750/3750 [00:13<00:00, 269.07it/s]\n",
      "Epoch 2 - Acc: 74.39%: 100%|██████████| 3750/3750 [00:16<00:00, 223.35it/s]\n",
      "Epoch 3 - Acc: 86.65%: 100%|██████████| 3750/3750 [00:11<00:00, 339.49it/s]\n",
      "Epoch 4 - Acc: 88.93%: 100%|██████████| 3750/3750 [00:10<00:00, 365.02it/s]\n",
      "Epoch 5 - Acc: 89.95%: 100%|██████████| 3750/3750 [00:10<00:00, 359.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model : Accuracy = 90.48%, Cross-Entropy Error = 0.4474\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"DATA\"\n",
    "train_img = read_images(os.path.join(DATA_PATH, \"train-images.idx3-ubyte\"))\n",
    "train_label = read_labels(os.path.join(DATA_PATH, \"train-labels.idx1-ubyte\"))\n",
    "test_img = read_images(os.path.join(DATA_PATH, \"t10k-images.idx3-ubyte\"))\n",
    "test_label = read_labels(os.path.join(DATA_PATH, \"t10k-labels.idx1-ubyte\"))\n",
    "\n",
    "train_img = train_img.astype(np.float64) / 255.0\n",
    "test_img = test_img.astype(np.float64) / 255.0\n",
    "\n",
    "alpha = 0.05\n",
    "batch_size = 16\n",
    "layer_sizes = [784, 30, 10]\n",
    "epochs = 5\n",
    "\n",
    "net = ANN(layer_sizes, alpha, batch_size)\n",
    "\n",
    "Xtest = test_img.T\n",
    "Ytest = test_label\n",
    "\n",
    "init_acc = accuracy(net, Xtest, Ytest)\n",
    "\n",
    "N = train_img.shape[0]\n",
    "for ep in range(epochs):\n",
    "    idx = np.arange(N)\n",
    "    np.random.shuffle(idx)\n",
    "    ce_total = 0.0\n",
    "    n_batches = 0\n",
    "\n",
    "    batch_iter = range(0, N - batch_size + 1, batch_size)\n",
    "    acc = accuracy(net, Xtest, Ytest)\n",
    "    desc = f'Epoch {ep+1} - Acc: {acc*100:.2f}%'\n",
    "\n",
    "    for i in tqdm(batch_iter, desc=desc):\n",
    "        bidx = idx[i:i+batch_size]\n",
    "        x_b = train_img[bidx].T\n",
    "        y_b = one_hot(train_label[bidx], 10)\n",
    "\n",
    "        out = net.forward(x_b)\n",
    "        ce = cross_entropy_cpu(out, y_b)\n",
    "        ce_total += ce\n",
    "\n",
    "        net.backward(x_b, y_b)\n",
    "        n_batches += 1\n",
    "\n",
    "    ce_mean = ce_total / n_batches\n",
    "    acc = accuracy(net, Xtest, Ytest)\n",
    "\n",
    "final_ce = ce_total / n_batches\n",
    "final_acc = accuracy(net, Xtest, Ytest)\n",
    "print(\"Final Model : Accuracy = {:.2f}%, Cross-Entropy Error = {:.4f}\".format(final_acc*100, final_ce))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ECN_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
