{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_uint32(b):\n",
    "    return (b[0] << 24) | (b[1] << 16) | (b[2] << 8) | b[3]\n",
    "\n",
    "def read_labels(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        _ = f.read(4)\n",
    "        n = make_uint32(f.read(4))\n",
    "        labels = np.frombuffer(f.read(n), dtype=np.uint8)\n",
    "    return labels\n",
    "\n",
    "def read_images(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        _ = f.read(4)\n",
    "        n = make_uint32(f.read(4))\n",
    "        rows = make_uint32(f.read(4))\n",
    "        cols = make_uint32(f.read(4))\n",
    "        images = np.frombuffer(f.read(n * rows * cols), dtype=np.uint8).reshape(n, rows*cols)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kernel index calculation**\n",
    "\n",
    "```python\n",
    "tx = cuda.threadIdx.x\n",
    "ty = cuda.threadIdx.y\n",
    "bx = cuda.blockIdx.x\n",
    "by = cuda.blockIdx.y\n",
    "bw = cuda.blockDim.x\n",
    "bh = cuda.blockDim.y\n",
    "x = tx + bx * bw\n",
    "y = ty + by * bh\n",
    "```\n",
    "\n",
    "OR :\n",
    "\n",
    "```python\n",
    "x, y = cuda.grid(2)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def matmul_kernel(A, B, C):\n",
    "    i, j = cuda.grid(2)\n",
    "    if i < C.shape[0] and j < C.shape[1]:\n",
    "        s = 0.0\n",
    "        for k in range(A.shape[1]):\n",
    "            s += A[i, k] * B[k, j]\n",
    "        C[i, j] = s\n",
    "\n",
    "@cuda.jit\n",
    "def add_bias_kernel(Z, b):\n",
    "    i, j = cuda.grid(2)\n",
    "    if i < Z.shape[0] and j < Z.shape[1]:\n",
    "        Z[i, j] += b[i, 0]\n",
    "\n",
    "@cuda.jit\n",
    "def sigmoid_kernel(A):\n",
    "    i, j = cuda.grid(2)\n",
    "    if i < A.shape[0] and j < A.shape[1]:\n",
    "        A[i, j] = 1.0 / (1.0 + math.exp(-A[i, j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grid(shape, tpb):\n",
    "    return (math.ceil(shape[0] / tpb[0]), math.ceil(shape[1] / tpb[1]))\n",
    "\n",
    "def gpu_matmul(A, B):\n",
    "    A_gpu = cuda.to_device(A)\n",
    "    B_gpu = cuda.to_device(B)\n",
    "    C = np.empty((A.shape[0], B.shape[1]), dtype=np.float64)\n",
    "    C_gpu = cuda.to_device(C)\n",
    "    dev = cuda.get_current_device()\n",
    "    tpb = (int(math.sqrt(dev.MAX_THREADS_PER_BLOCK)), int(math.sqrt(dev.MAX_THREADS_PER_BLOCK)))\n",
    "    grid = get_grid(C.shape, tpb)\n",
    "    matmul_kernel[grid, tpb](A_gpu, B_gpu, C_gpu)\n",
    "    C_gpu.copy_to_host(C)\n",
    "    return C\n",
    "\n",
    "def gpu_add_bias(Z, b):\n",
    "    Z_gpu = cuda.to_device(Z)\n",
    "    b_gpu = cuda.to_device(b)\n",
    "    dev = cuda.get_current_device()\n",
    "    tpb = (int(math.sqrt(dev.MAX_THREADS_PER_BLOCK)), int(math.sqrt(dev.MAX_THREADS_PER_BLOCK)))\n",
    "    grid = get_grid(Z.shape, tpb)\n",
    "    add_bias_kernel[grid, tpb](Z_gpu, b_gpu)\n",
    "    Z_gpu.copy_to_host(Z)\n",
    "    return Z\n",
    "\n",
    "def gpu_sigmoid(A):\n",
    "    A_gpu = cuda.to_device(A)\n",
    "    dev = cuda.get_current_device()\n",
    "    tpb = (int(math.sqrt(dev.MAX_THREADS_PER_BLOCK)), int(math.sqrt(dev.MAX_THREADS_PER_BLOCK)))\n",
    "    grid = get_grid(A.shape, tpb)\n",
    "    sigmoid_kernel[grid, tpb](A_gpu)\n",
    "    A_gpu.copy_to_host(A)\n",
    "    return A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0/(1.0+np.exp(-x))\n",
    "def dsigmoid(x):\n",
    "    s = sigmoid(x)\n",
    "    return s*(1-s)\n",
    "\n",
    "class ANN:\n",
    "    def __init__(self, sizes, alpha, minibatch_size):\n",
    "        self.alpha = alpha\n",
    "        self.minibatch = minibatch_size\n",
    "        self.L = len(sizes)-1\n",
    "        self.W = [np.random.randn(sizes[i+1], sizes[i]) / np.sqrt(sizes[i])\n",
    "                  for i in range(self.L)]\n",
    "        self.b = [np.zeros((sizes[i+1],1)) for i in range(self.L)]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        a = x.copy()\n",
    "        self.z_list= []\n",
    "        self.a_list = [a]\n",
    "        for l in range(self.L):\n",
    "            z = gpu_matmul(self.W[l], a)\n",
    "            z = gpu_add_bias(z, self.b[l])\n",
    "            self.z_list.append(z)\n",
    "            a = gpu_sigmoid(z)\n",
    "            self.a_list.append(a)\n",
    "        return a\n",
    "\n",
    "    def backward(self, x, y):\n",
    "        # Compute gradients via backpropagation (on CPU)\n",
    "        L = self.L\n",
    "        delta = (self.a_list[-1] - y) * dsigmoid(self.z_list[-1])\n",
    "        gradW = [None]*L\n",
    "        gradb = [None]*L\n",
    "        gradW[L-1] = np.dot(delta, self.a_list[L-1].T) / self.minibatch\n",
    "        gradb[L-1] = np.sum(delta, axis=1, keepdims=True) / self.minibatch\n",
    "        for l in range(L-2, -1, -1):\n",
    "            delta = np.dot(self.W[l+1].T, delta) * dsigmoid(self.z_list[l])\n",
    "            gradW[l] = np.dot(delta, self.a_list[l].T) / self.minibatch\n",
    "            gradb[l] = np.sum(delta, axis=1, keepdims=True) / self.minibatch\n",
    "        # Update weights and biases\n",
    "        for l in range(L):\n",
    "            self.W[l] -= self.alpha * gradW[l]\n",
    "            self.b[l] -= self.alpha * gradb[l]\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        n = X.shape[1]\n",
    "        output = self.forward(X)\n",
    "        predictions = np.argmax(output, axis=0)\n",
    "        return np.sum(predictions == y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3750 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3750/3750 [00:31<00:00, 118.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Acc: 80.80%, CE: 1.3444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3750/3750 [00:52<00:00, 70.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Acc: 84.40%, CE: 0.7748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3750/3750 [00:50<00:00, 74.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Acc: 84.00%, CE: 0.6675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3750/3750 [00:52<00:00, 71.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Acc: 83.80%, CE: 0.6162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3750/3750 [00:55<00:00, 67.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Acc: 85.40%, CE: 0.5782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training settings and main loop\n",
    "DATA_PATH = \"DATA\"\n",
    "train_img = read_images(os.path.join(DATA_PATH, \"train-images.idx3-ubyte\"))\n",
    "train_label = read_labels(os.path.join(DATA_PATH, \"train-labels.idx1-ubyte\"))\n",
    "test_img = read_images(os.path.join(DATA_PATH, \"t10k-images.idx3-ubyte\"))\n",
    "test_label = read_labels(os.path.join(DATA_PATH, \"t10k-labels.idx1-ubyte\"))\n",
    "\n",
    "alpha = 0.05\n",
    "minibatch = 16\n",
    "sizes = [784, 30, 10]\n",
    "net = ANN(sizes, alpha, minibatch)\n",
    "NEPOCHS = 5\n",
    "\n",
    "def one_hot(indices, n_classes):\n",
    "    m = np.zeros((n_classes, len(indices)))\n",
    "    m[indices, np.arange(len(indices))] = 1.0\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = train_img.shape[0]\n",
    "for epoch in range(NEPOCHS):\n",
    "    indices = np.arange(N_train)\n",
    "    np.random.shuffle(indices)\n",
    "    ce_total = 0.0\n",
    "    n_batches = 0\n",
    "    for i in tqdm(range(0, N_train - minibatch + 1, minibatch)):\n",
    "        batch_idx = indices[i:i+minibatch]\n",
    "        x = (train_img[batch_idx].T.astype(np.float64)) / 255.0\n",
    "        y = one_hot(train_label[batch_idx], 10)\n",
    "        output = net.forward(x)\n",
    "        # Cross-entropy loss (CPU)\n",
    "        eps = 1e-12\n",
    "        output_clip = np.clip(output, eps, 1-eps)\n",
    "        ce = -np.sum(y * np.log(output_clip)) / minibatch\n",
    "        ce_total += ce\n",
    "        net.backward(x, y)\n",
    "        n_batches += 1\n",
    "    acc = net.evaluate((test_img[:1000].T.astype(np.float64))/255.0, test_label[:1000])\n",
    "    print(f\"Epoch {epoch} - Acc: {100.0*acc/1000:.2f}%, CE: {ce_total/n_batches:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy: 85.40%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation on test set (using first 1000 examples for speed)\n",
    "acc = net.evaluate((test_img[:1000].T.astype(np.float64))/255.0, test_label[:1000])\n",
    "print(f\"Final Test Accuracy: {100.0*acc/1000:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
