{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numba as nb\n",
    "from numba import cuda\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1. Lecture des fichiers MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_uint32(byte_array):\n",
    "    \"\"\" Recompose un entier 32 bits à partir de 4 octets de poids fort à poids faible \"\"\"\n",
    "    return ((byte_array[0] << 24) \n",
    "          | (byte_array[1] << 16) \n",
    "          | (byte_array[2] <<  8) \n",
    "          | (byte_array[3] <<  0))\n",
    "\n",
    "def read_labels(filename):\n",
    "    \"\"\" Lit un fichier de labels MNIST \"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        _ = f.read(4)  # Magic number (non utilisé)\n",
    "        n_bytes = f.read(4)\n",
    "        n = make_uint32(n_bytes)\n",
    "        labels = np.frombuffer(f.read(n), dtype=np.uint8)\n",
    "    return labels\n",
    "\n",
    "def read_images(filename):\n",
    "    \"\"\" Lit un fichier d'images MNIST \"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        _ = f.read(4)  # Magic number (non utilisé)\n",
    "        n_bytes = f.read(4)\n",
    "        n = make_uint32(n_bytes)\n",
    "        row_bytes = f.read(4)\n",
    "        col_bytes = f.read(4)\n",
    "        rows = make_uint32(row_bytes)\n",
    "        cols = make_uint32(col_bytes)\n",
    "        images_raw = f.read(n * rows * cols)\n",
    "        images = np.frombuffer(images_raw, dtype=np.uint8)\n",
    "        images = images.reshape(n, rows * cols)\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2. Fonctions utilitaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_to_n(n):\n",
    "    \"\"\" Crée un tableau [0, 1, 2, ..., n-1] \"\"\"\n",
    "    return np.arange(n, dtype=np.uint32)\n",
    "\n",
    "def shuffle(t, number_of_switch):\n",
    "    \"\"\" Mélange un tableau t aléatoirement, en réalisant 'number_of_switch' échanges \"\"\"\n",
    "    size = len(t)\n",
    "    for _ in range(number_of_switch):\n",
    "        x = np.random.randint(0, size)\n",
    "        y = np.random.randint(0, size)\n",
    "        tmp = t[x]\n",
    "        t[x] = t[y]\n",
    "        t[y] = tmp\n",
    "        \n",
    "def init_sigma(nneurons_prev):\n",
    "    return 1.0 / np.sqrt(nneurons_prev)\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\" Fonction d'activation vectorisée \"\"\"\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def dsigmoid(x):\n",
    "    \"\"\" Dérivée de sigmoid vectorisée \"\"\"\n",
    "    s = sigmoid(x)\n",
    "    return s * (1.0 - s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 3. Fonctions Matricielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alloc_matrix(rows, columns):\n",
    "    # En C, on fait un malloc puis un tableau 1D rows*columns.\n",
    "    # En Python, on crée un np.ndarray de shape (rows, columns).\n",
    "    return np.zeros((rows, columns), dtype=np.float64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 3.3. Version Parallèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def matrix_dot_cuda(m1, m2, res, nrow1, ncol1, ncol2):\n",
    "    row, col = cuda.grid(2)\n",
    "    if row < nrow1 and col < ncol2:\n",
    "        tmp = 0.0\n",
    "        for k in range(ncol1):\n",
    "            tmp += m1[row, k] * m2[k, col]\n",
    "        res[row, col] = tmp\n",
    "\n",
    "@cuda.jit\n",
    "def matrix_sum_cuda(m1, m2, res, nrow, ncol):\n",
    "    row, col = cuda.grid(2)\n",
    "    if row < nrow and col < ncol:\n",
    "        res[row, col] = m1[row, col] + m2[row, col]\n",
    "\n",
    "@cuda.jit\n",
    "def matrix_minus_cuda(m1, m2, res, nrow, ncol):\n",
    "    row, col = cuda.grid(2)\n",
    "    if row < nrow and col < ncol:\n",
    "        res[row, col] = m1[row, col] - m2[row, col]\n",
    "\n",
    "@cuda.jit\n",
    "def hadamard_product_cuda(m1, m2, res, nrow, ncol):\n",
    "    row, col = cuda.grid(2)\n",
    "    if row < nrow and col < ncol:\n",
    "        res[row, col] = m1[row, col] * m2[row, col]\n",
    "\n",
    "@cuda.jit\n",
    "def matrix_transpose_cuda(m, res, nrow, ncol):\n",
    "    row, col = cuda.grid(2)\n",
    "    if row < nrow and col < ncol:\n",
    "        res[col, row] = m[row, col]\n",
    "\n",
    "@cuda.jit\n",
    "def matrix_scalar_cuda(m, res, scalar, nrow, ncol):\n",
    "    row, col = cuda.grid(2)\n",
    "    if row < nrow and col < ncol:\n",
    "        res[row, col] = m[row, col] * scalar\n",
    "\n",
    "@cuda.jit\n",
    "def matrix_memcpy_cuda(dest, src, nrow, ncol):\n",
    "    row, col = cuda.grid(2)\n",
    "    if row < nrow and col < ncol:\n",
    "        dest[row, col] = src[row, col]\n",
    "        \n",
    "@cuda.jit\n",
    "def matrix_function_id_cuda(m_in, m_out, nrow, ncol, func_id):\n",
    "    \"\"\"\n",
    "    Applique la fonction correspondant à func_id :\n",
    "      0 -> exp\n",
    "      1 -> sigmoid\n",
    "      2 -> dsigmoid\n",
    "      ...\n",
    "    \"\"\"\n",
    "    row, col = cuda.grid(2)\n",
    "    if row < nrow and col < ncol:\n",
    "        val = m_in[row, col]\n",
    "        if func_id == 0:\n",
    "            result = math.exp(val)\n",
    "        elif func_id == 1:\n",
    "            result = 1.0 / (1.0 + math.exp(-val))\n",
    "        elif func_id == 2:\n",
    "            s = 1.0 / (1.0 + math.exp(-val))\n",
    "            result = s * (1.0 - s)\n",
    "        else:\n",
    "            result = val\n",
    "        m_out[row, col] = result\n",
    "\n",
    "def matrix_dot_parallel(m1, m2):\n",
    "    nrow1, ncol1 = m1.shape; nrow2, ncol2 = m2.shape; \n",
    "    if ncol1 != nrow2: raise ValueError(\"Incompatible matrix dimensions\")\n",
    "    m1_gpu = cuda.to_device(m1)\n",
    "    m2_gpu = cuda.to_device(m2)\n",
    "    res_gpu = cuda.device_array((nrow1, ncol2), dtype=np.float64)\n",
    "    threads_per_block = (16,16)\n",
    "    blocks_per_grid = (math.ceil(ncol2/16), math.ceil(nrow1/16))\n",
    "    matrix_dot_cuda[blocks_per_grid, threads_per_block](m1_gpu, m2_gpu, res_gpu, nrow1, ncol1, ncol2)\n",
    "    return res_gpu.copy_to_host()\n",
    "\n",
    "def matrix_sum_parallel(m1, m2):\n",
    "    nrow, ncol = m1.shape\n",
    "    m1_gpu = cuda.to_device(m1); m2_gpu = cuda.to_device(m2)\n",
    "    res_gpu = cuda.device_array((nrow, ncol), dtype=np.float64)\n",
    "    threads_per_block = (16,16)\n",
    "    blocks_per_grid = (math.ceil(nrow/16), math.ceil(ncol/16))\n",
    "    matrix_sum_cuda[blocks_per_grid, threads_per_block](m1_gpu, m2_gpu, res_gpu, nrow, ncol)\n",
    "    return res_gpu.copy_to_host()\n",
    "\n",
    "def matrix_minus_parallel(m1, m2):\n",
    "    nrow, ncol = m1.shape\n",
    "    m1_gpu = cuda.to_device(m1); m2_gpu = cuda.to_device(m2)\n",
    "    res_gpu = cuda.device_array((nrow, ncol), dtype=np.float64)\n",
    "    threads_per_block = (16,16)\n",
    "    blocks_per_grid = (math.ceil(nrow/16), math.ceil(ncol/16))\n",
    "    matrix_minus_cuda[blocks_per_grid, threads_per_block](m1_gpu, m2_gpu, res_gpu, nrow, ncol)\n",
    "    return res_gpu.copy_to_host()\n",
    "\n",
    "def hadamard_product_parallel(m1, m2):\n",
    "    nrow, ncol = m1.shape\n",
    "    m1_gpu = cuda.to_device(m1); m2_gpu = cuda.to_device(m2)\n",
    "    res_gpu = cuda.device_array((nrow, ncol), dtype=np.float64)\n",
    "    threads_per_block = (16,16)\n",
    "    blocks_per_grid = (math.ceil(nrow/16), math.ceil(ncol/16))\n",
    "    hadamard_product_cuda[blocks_per_grid, threads_per_block](m1_gpu, m2_gpu, res_gpu, nrow, ncol)\n",
    "    return res_gpu.copy_to_host()\n",
    "\n",
    "def matrix_transpose_parallel(m):\n",
    "    nrow, ncol = m.shape\n",
    "    m_gpu = cuda.to_device(m)\n",
    "    res_gpu = cuda.device_array((ncol, nrow), dtype=np.float64)\n",
    "    threads_per_block = (16,16)\n",
    "    blocks_per_grid = (math.ceil(nrow/16), math.ceil(ncol/16))\n",
    "    matrix_transpose_cuda[blocks_per_grid, threads_per_block](m_gpu, res_gpu, nrow, ncol)\n",
    "    return res_gpu.copy_to_host()\n",
    "\n",
    "def matrix_scalar_parallel(m, s):\n",
    "    nrow, ncol = m.shape\n",
    "    m_gpu = cuda.to_device(m)\n",
    "    res_gpu = cuda.device_array((nrow, ncol), dtype=np.float64)\n",
    "    threads_per_block = (16,16)\n",
    "    blocks_per_grid = (math.ceil(nrow/16), math.ceil(ncol/16))\n",
    "    matrix_scalar_cuda[blocks_per_grid, threads_per_block](m_gpu, res_gpu, s, nrow, ncol)\n",
    "    return res_gpu.copy_to_host()\n",
    "\n",
    "def matrix_memcpy_parallel(dest, src):\n",
    "    nrow, ncol = src.shape\n",
    "    dest_gpu = cuda.to_device(dest); src_gpu = cuda.to_device(src)\n",
    "    threads_per_block = (16,16)\n",
    "    blocks_per_grid = (math.ceil(nrow/16), math.ceil(ncol/16))\n",
    "    matrix_memcpy_cuda[blocks_per_grid, threads_per_block](dest_gpu, src_gpu, nrow, ncol)\n",
    "    dest[:] = dest_gpu.copy_to_host()\n",
    "\n",
    "def matrix_function_parallel(m1, func_name):\n",
    "    func_id = 0 if func_name == \"exp\" else \\\n",
    "              1 if func_name == \"sigmoid\" else \\\n",
    "              2 if func_name == \"dsigmoid\" else \\\n",
    "              None\n",
    "    if func_id is None: raise ValueError(f\"Unknown function ID : {func_name}\")\n",
    "    nrow, ncol = m1.shape\n",
    "    m1_gpu = cuda.to_device(m1)\n",
    "    res_gpu = cuda.device_array((nrow, ncol), dtype=np.float64)\n",
    "    threads_per_block = (16,16)\n",
    "    blocks_per_grid = (math.ceil(nrow/16), math.ceil(ncol/16))\n",
    "    matrix_function_id_cuda[blocks_per_grid, threads_per_block](m1_gpu, res_gpu, nrow, ncol, func_id)\n",
    "    return res_gpu.copy_to_host()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 4. Réseau de Neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, layer_number, number_of_neurons, nneurons_previous_layer, minibatch_size):\n",
    "        self.number_of_neurons = number_of_neurons\n",
    "        self.minibatch_size = minibatch_size\n",
    "        self.activations = alloc_matrix(number_of_neurons, minibatch_size)\n",
    "        self.z           = alloc_matrix(number_of_neurons, minibatch_size)\n",
    "        self.delta       = alloc_matrix(number_of_neurons, minibatch_size)\n",
    "        self.weights     = alloc_matrix(number_of_neurons, nneurons_previous_layer)\n",
    "        self.biases      = alloc_matrix(number_of_neurons, 1)\n",
    "        \n",
    "        if layer_number > 0:\n",
    "            self.init_weight(nneurons_previous_layer)\n",
    "    \n",
    "    def init_weight(self, nneurons_prev):\n",
    "        sigma = init_sigma(nneurons_prev)\n",
    "        r, c = self.weights.shape\n",
    "        self.weights = np.random.normal(0.0, sigma, size=(r, c))\n",
    "\n",
    "class ANN:\n",
    "    def __init__(self, alpha, minibatch_size, number_of_layers, nneurons_per_layer):\n",
    "        self.alpha = alpha\n",
    "        self.minibatch_size = minibatch_size\n",
    "        self.number_of_layers = number_of_layers\n",
    "        self.layers = []\n",
    "        for i in range(number_of_layers):\n",
    "            if i == 0:\n",
    "                self.layers.append(\n",
    "                    Layer(i, nneurons_per_layer[i], \n",
    "                          nneurons_per_layer[i],  \n",
    "                          minibatch_size)\n",
    "                )\n",
    "            else:\n",
    "                self.layers.append(\n",
    "                    Layer(i, nneurons_per_layer[i],\n",
    "                          nneurons_per_layer[i-1],\n",
    "                          minibatch_size)\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_input_parallel(nn, input_matrix):\n",
    "    matrix_memcpy_parallel(nn.layers[0].activations, input_matrix)\n",
    "\n",
    "def forward_parallel(nn):\n",
    "    for l in range(1, nn.number_of_layers):\n",
    "        layer_l = nn.layers[l]\n",
    "        layer_prev = nn.layers[l-1]\n",
    "        z1 = matrix_dot_parallel(layer_l.weights, layer_prev.activations)\n",
    "        ones = np.ones((1, nn.minibatch_size), dtype=np.float64)\n",
    "        z2 = matrix_dot_parallel(layer_l.biases, ones)\n",
    "        layer_l.z = matrix_sum_parallel(z1, z2)\n",
    "        layer_l.activations = matrix_function_parallel(layer_l.z, \"sigmoid\")\n",
    "\n",
    "def backward_parallel(nn, y):\n",
    "    L = nn.number_of_layers - 1\n",
    "    layer_L = nn.layers[L]\n",
    "    tmp = matrix_minus_parallel(layer_L.activations, y)\n",
    "    dfzL = matrix_function_parallel(layer_L.z, \"dsigmoid\")\n",
    "    layer_L.delta = hadamard_product_parallel(tmp, dfzL)\n",
    "    for l in range(L, 1, -1):\n",
    "        layer_l = nn.layers[l]\n",
    "        layer_lm1 = nn.layers[l-1]\n",
    "        w_l_transp = matrix_transpose_parallel(layer_l.weights)\n",
    "        delta_tmp = matrix_dot_parallel(w_l_transp, layer_l.delta)\n",
    "        dfz = matrix_function_parallel(layer_lm1.z, \"dsigmoid\")\n",
    "        layer_lm1.delta = hadamard_product_parallel(delta_tmp, dfz)\n",
    "    for l in range(1, nn.number_of_layers):\n",
    "        layer_l = nn.layers[l]\n",
    "        layer_lm1 = nn.layers[l-1]\n",
    "        a_lm1_transp = matrix_transpose_parallel(layer_lm1.activations)\n",
    "        w1 = matrix_dot_parallel(layer_l.delta, a_lm1_transp)\n",
    "        w1 = matrix_scalar_parallel(w1, nn.alpha / nn.minibatch_size)\n",
    "        layer_l.weights = matrix_minus_parallel(layer_l.weights, w1)\n",
    "        ones = np.ones((nn.minibatch_size, 1), dtype=np.float64)\n",
    "        b1 = matrix_dot_parallel(layer_l.delta, ones)\n",
    "        b1 = matrix_scalar_parallel(b1, nn.alpha / nn.minibatch_size)\n",
    "        layer_l.biases = matrix_minus_parallel(layer_l.biases, b1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 5. Fonctions d'entraînement (Version Parallèle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_parallel(x, y, minibatch_idx, train_img, train_label):\n",
    "    \"\"\"\n",
    "    Remplit les matrices x et y avec le mini-batch.\n",
    "    x -> shape (784, minibatch_size)\n",
    "    y -> shape (10, minibatch_size)\n",
    "    \"\"\"\n",
    "    x_batch = train_img[minibatch_idx].astype(np.float64) / 255.0\n",
    "    matrix_memcpy_parallel(x, x_batch.T)  # Transpose pour avoir (784, batch_size)\n",
    "    y.fill(0.0)\n",
    "    indices = train_label[minibatch_idx]\n",
    "    y[indices, np.arange(len(minibatch_idx))] = 1.0\n",
    "\n",
    "def accuracy_parallel(nn, test_img, test_label, minibatch_size):\n",
    "    \"\"\"\n",
    "    Compute the accuracy (%) on the test set using parallel matrix operations.\n",
    "    \"\"\"\n",
    "    test_size = test_img.shape[0]\n",
    "    nbatches = (test_size // minibatch_size) * minibatch_size\n",
    "    correct = 0\n",
    "    for i in range(0, nbatches, minibatch_size):\n",
    "        batch_indices = np.arange(i, i + minibatch_size)\n",
    "        x = test_img[batch_indices].T.astype(np.float64) / 255.0\n",
    "        set_input_parallel(nn, x)\n",
    "        forward_parallel(nn)\n",
    "        preds = np.argmax(nn.layers[-1].activations, axis=0)\n",
    "        correct += np.sum(preds == test_label[batch_indices])\n",
    "    return (100.0 * correct) / nbatches\n",
    "\n",
    "def cross_entropy_parallel(y_pred, y_true, eps=1e-12):\n",
    "    \"\"\"\n",
    "    Compute cross-entropy error for a mini-batch using parallel operations.\n",
    "    \"\"\"\n",
    "    y_pred = np.clip(y_pred, eps, 1.0 - eps)\n",
    "    return -np.sum(y_true * np.log(y_pred)) / y_true.shape[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 6. Lecture des données MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de données d'entraînement : 60000\n",
      "Nombre de données de test : 10000\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"DATA\"\n",
    "\n",
    "train_img = read_images(os.path.join(DATA_PATH, \"train-images.idx3-ubyte\"))\n",
    "train_label = read_labels(os.path.join(DATA_PATH, \"train-labels.idx1-ubyte\"))\n",
    "test_img = read_images(os.path.join(DATA_PATH, \"t10k-images.idx3-ubyte\"))\n",
    "test_label = read_labels(os.path.join(DATA_PATH, \"t10k-labels.idx1-ubyte\"))\n",
    "\n",
    "train_size = train_img.shape[0]\n",
    "test_size = test_img.shape[0]\n",
    "print(f\"Nombre de données d'entraînement : {train_size}\")\n",
    "print(f\"Nombre de données de test : {test_size}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4. Entraînement du réseau (Version Parallèle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sacha\\miniconda3\\envs\\ECN_GPU\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 49 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "c:\\Users\\sacha\\miniconda3\\envs\\ECN_GPU\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "c:\\Users\\sacha\\miniconda3\\envs\\ECN_GPU\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "c:\\Users\\sacha\\miniconda3\\envs\\ECN_GPU\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "c:\\Users\\sacha\\miniconda3\\envs\\ECN_GPU\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "Epoch 0 - Acc: 10.40%:   0%|          | 0/3750 [00:00<?, ?it/s]c:\\Users\\sacha\\miniconda3\\envs\\ECN_GPU\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "c:\\Users\\sacha\\miniconda3\\envs\\ECN_GPU\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "c:\\Users\\sacha\\miniconda3\\envs\\ECN_GPU\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "c:\\Users\\sacha\\miniconda3\\envs\\ECN_GPU\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "c:\\Users\\sacha\\miniconda3\\envs\\ECN_GPU\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 49 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "c:\\Users\\sacha\\miniconda3\\envs\\ECN_GPU\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 98 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "c:\\Users\\sacha\\miniconda3\\envs\\ECN_GPU\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 98 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "c:\\Users\\sacha\\miniconda3\\envs\\ECN_GPU\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "c:\\Users\\sacha\\miniconda3\\envs\\ECN_GPU\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "Epoch 0 - Acc: 10.40%: 100%|██████████| 3750/3750 [02:05<00:00, 29.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Acc: 13.79%, CE: 2.2423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Acc: 14.53%: 100%|██████████| 3750/3750 [02:00<00:00, 31.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Acc: 15.84%, CE: 2.3240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Acc: 16.67%: 100%|██████████| 3750/3750 [01:54<00:00, 32.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Acc: 17.92%, CE: 2.2923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Acc: 18.88%: 100%|██████████| 3750/3750 [01:56<00:00, 32.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Acc: 19.87%, CE: 2.2639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Acc: 20.26%:  63%|██████▎   | 2380/3750 [01:12<00:51, 26.41it/s]"
     ]
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "minibatch_size = 16\n",
    "number_of_layers = 3\n",
    "nneurons_per_layer = [784, 30, 10]  # 28*28 = 784\n",
    "nn = ANN(alpha, minibatch_size, number_of_layers, nneurons_per_layer)\n",
    "\n",
    "shuffled_idx = zero_to_n(train_size)\n",
    "x = alloc_matrix(784, minibatch_size)\n",
    "y = alloc_matrix(10, minibatch_size)\n",
    "\n",
    "NEPOCHS = 5\n",
    "\n",
    "for epoch in range(NEPOCHS):\n",
    "    shuffle(shuffled_idx, train_size)\n",
    "    nbatches = (train_size // minibatch_size) * minibatch_size\n",
    "    batch_iter = range(0, nbatches, minibatch_size)\n",
    "    ce_total = 0.0\n",
    "    n_train_batches = 0\n",
    "    acc = accuracy_parallel(nn, test_img, test_label, minibatch_size)\n",
    "    desc = f'Epoch {epoch} - Acc: {acc:.2f}%'\n",
    "    for i in tqdm(batch_iter, desc=desc):\n",
    "        batch_indices = shuffled_idx[i : i + minibatch_size]\n",
    "        populate_parallel(x, y, batch_indices, train_img, train_label)\n",
    "        set_input_parallel(nn, x)\n",
    "        forward_parallel(nn)\n",
    "        y_pred = nn.layers[-1].activations  \n",
    "        ce_batch = cross_entropy_parallel(y_pred, y)\n",
    "        ce_total += ce_batch\n",
    "        n_train_batches += 1\n",
    "        backward_parallel(nn, y)\n",
    "    ce_mean = ce_total / n_train_batches\n",
    "    acc = accuracy_parallel(nn, test_img, test_label, minibatch_size)\n",
    "    print(f'Epoch {epoch} - Acc: {acc:.2f}%, CE: {ce_mean:.4f}')\n",
    "\n",
    "acc_end = accuracy_parallel(nn, test_img, test_label, minibatch_size)\n",
    "ce_end = cross_entropy_parallel(y_pred, y)\n",
    "print(\"Final Model : Accuracy = {:.2f}%, Cross-Entropy Error = {:.4f}\".format(acc_end, ce_end))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ECN_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
