{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Minimal MNIST Readers (CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_uint32(b):\n",
    "    return (b[0] << 24) | (b[1] << 16) | (b[2] << 8) | b[3]\n",
    "\n",
    "def read_labels(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        _ = f.read(4)  # magic\n",
    "        n = make_uint32(f.read(4))\n",
    "        data = np.frombuffer(f.read(n), dtype=np.uint8)\n",
    "    return data\n",
    "\n",
    "def read_images(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        _ = f.read(4)  # magic\n",
    "        n = make_uint32(f.read(4))\n",
    "        rows = make_uint32(f.read(4))\n",
    "        cols = make_uint32(f.read(4))\n",
    "        data = np.frombuffer(f.read(n * rows * cols), dtype=np.uint8)\n",
    "        data = data.reshape(n, rows * cols)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # GPU Kernels for Matrix Operations\n",
    "\n",
    "\n",
    "\n",
    " We keep all major ops on the GPU:\n",
    "\n",
    " - Dot product (matrix multiplication)\n",
    "\n",
    " - Hadamard (elementwise product)\n",
    "\n",
    " - Subtract (elementwise)\n",
    "\n",
    " - Sigmoid (in-place)\n",
    "\n",
    " - dSigmoid\n",
    "\n",
    " - Transpose\n",
    "\n",
    " - Sum of columns\n",
    "\n",
    " - Scalar multiplication\n",
    "\n",
    " - Add bias (broadcast over columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def dot_product_kernel(A, B, C):\n",
    "    \"\"\"\n",
    "    C = A x B\n",
    "    A.shape = (m, k)\n",
    "    B.shape = (k, n)\n",
    "    C.shape = (m, n)\n",
    "    \"\"\"\n",
    "    i, j = cuda.grid(2)\n",
    "    if i < C.shape[0] and j < C.shape[1]:\n",
    "        tmp = 0.0\n",
    "        for kk in range(A.shape[1]):\n",
    "            tmp += A[i, kk] * B[kk, j]\n",
    "        C[i, j] = tmp\n",
    "\n",
    "@cuda.jit\n",
    "def hadamard_kernel(A, B, C):\n",
    "    \"\"\"\n",
    "    C = A * B (elementwise)\n",
    "    \"\"\"\n",
    "    i, j = cuda.grid(2)\n",
    "    if i < A.shape[0] and j < A.shape[1]:\n",
    "        C[i, j] = A[i, j] * B[i, j]\n",
    "\n",
    "@cuda.jit\n",
    "def subtract_kernel(A, B, C):\n",
    "    \"\"\"\n",
    "    C = A - B (elementwise)\n",
    "    \"\"\"\n",
    "    i, j = cuda.grid(2)\n",
    "    if i < A.shape[0] and j < A.shape[1]:\n",
    "        C[i, j] = A[i, j] - B[i, j]\n",
    "\n",
    "@cuda.jit\n",
    "def sigmoid_kernel(A):\n",
    "    \"\"\"\n",
    "    In-place Sigmoid: A[i,j] = 1/(1+exp(-A[i,j]))\n",
    "    \"\"\"\n",
    "    i, j = cuda.grid(2)\n",
    "    if i < A.shape[0] and j < A.shape[1]:\n",
    "        A[i, j] = 1.0 / (1.0 + math.exp(-A[i, j]))\n",
    "\n",
    "@cuda.jit\n",
    "def dsigmoid_kernel(Z, Out):\n",
    "    \"\"\"\n",
    "    Out[i,j] = derivative of sigmoid at Z[i,j].\n",
    "    Recomputes s = 1/(1+exp(-Z[i,j])) then s*(1-s).\n",
    "    \"\"\"\n",
    "    i, j = cuda.grid(2)\n",
    "    if i < Z.shape[0] and j < Z.shape[1]:\n",
    "        s = 1.0 / (1.0 + math.exp(-Z[i, j]))\n",
    "        Out[i, j] = s * (1.0 - s)\n",
    "\n",
    "@cuda.jit\n",
    "def transpose_kernel(A, T):\n",
    "    \"\"\"\n",
    "    T = A^T\n",
    "    A.shape = (r, c)\n",
    "    T.shape = (c, r)\n",
    "    \"\"\"\n",
    "    i, j = cuda.grid(2)\n",
    "    if i < A.shape[0] and j < A.shape[1]:\n",
    "        T[j, i] = A[i, j]\n",
    "\n",
    "@cuda.jit\n",
    "def sum_columns_kernel(A, column_sum):\n",
    "    \"\"\"\n",
    "    Sums each row's elements across columns.\n",
    "    A.shape = (m, n), column_sum.shape = (m, 1)\n",
    "    column_sum[i,0] = sum over j of A[i,j]\n",
    "    \"\"\"\n",
    "    i = cuda.grid(1)\n",
    "    if i < A.shape[0]:\n",
    "        s = 0.0\n",
    "        for j in range(A.shape[1]):\n",
    "            s += A[i, j]\n",
    "        column_sum[i, 0] = s\n",
    "\n",
    "@cuda.jit\n",
    "def scalar_mul_kernel(A, scalar, Out):\n",
    "    \"\"\"\n",
    "    Out = A * scalar (elementwise)\n",
    "    \"\"\"\n",
    "    i, j = cuda.grid(2)\n",
    "    if i < A.shape[0] and j < A.shape[1]:\n",
    "        Out[i, j] = A[i, j] * scalar\n",
    "\n",
    "@cuda.jit\n",
    "def add_bias_kernel(A, bias, Out):\n",
    "    \"\"\"\n",
    "    Broadcast bias (shape (m,1)) across columns of A (shape (m,n)).\n",
    "    Out[i,j] = A[i,j] + bias[i,0]\n",
    "    \"\"\"\n",
    "    i, j = cuda.grid(2)\n",
    "    if i < A.shape[0] and j < A.shape[1]:\n",
    "        Out[i, j] = A[i, j] + bias[i, 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # GPU Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_2d(shape, block=(16,16)):\n",
    "    \"\"\"\n",
    "    Return a 2D grid for shape (rows, cols).\n",
    "    \"\"\"\n",
    "    gx = (shape[0] + block[0] - 1) // block[0]\n",
    "    gy = (shape[1] + block[1] - 1) // block[1]\n",
    "    return (gx, gy)\n",
    "\n",
    "def dot_product_gpu(A, B):\n",
    "    \"\"\"\n",
    "    GPU: return A@B\n",
    "    \"\"\"\n",
    "    A_gpu = cuda.to_device(A)\n",
    "    B_gpu = cuda.to_device(B)\n",
    "    C = np.empty((A.shape[0], B.shape[1]), dtype=np.float64)\n",
    "    C_gpu = cuda.device_array_like(C)\n",
    "    block = (16,16)\n",
    "    grid = grid_2d(C.shape, block)\n",
    "    dot_product_kernel[grid, block](A_gpu, B_gpu, C_gpu)\n",
    "    C_gpu.copy_to_host(C)\n",
    "    return C\n",
    "\n",
    "def hadamard_gpu(A, B):\n",
    "    \"\"\"\n",
    "    GPU: C = A * B elementwise\n",
    "    \"\"\"\n",
    "    A_gpu = cuda.to_device(A)\n",
    "    B_gpu = cuda.to_device(B)\n",
    "    out = np.empty_like(A)\n",
    "    out_gpu = cuda.device_array_like(out)\n",
    "    block = (16,16)\n",
    "    grid = grid_2d(A.shape, block)\n",
    "    hadamard_kernel[grid, block](A_gpu, B_gpu, out_gpu)\n",
    "    out_gpu.copy_to_host(out)\n",
    "    return out\n",
    "\n",
    "def subtract_gpu(A, B):\n",
    "    \"\"\"\n",
    "    GPU: C = A - B elementwise\n",
    "    \"\"\"\n",
    "    A_gpu = cuda.to_device(A)\n",
    "    B_gpu = cuda.to_device(B)\n",
    "    out = np.empty_like(A)\n",
    "    out_gpu = cuda.device_array_like(out)\n",
    "    block = (16,16)\n",
    "    grid = grid_2d(A.shape, block)\n",
    "    subtract_kernel[grid, block](A_gpu, B_gpu, out_gpu)\n",
    "    out_gpu.copy_to_host(out)\n",
    "    return out\n",
    "\n",
    "def sigmoid_gpu(A):\n",
    "    \"\"\"\n",
    "    GPU: in-place sigmoid of A\n",
    "    Returns new array\n",
    "    \"\"\"\n",
    "    A_gpu = cuda.to_device(A)\n",
    "    block = (16,16)\n",
    "    grid = grid_2d(A.shape, block)\n",
    "    sigmoid_kernel[grid, block](A_gpu)\n",
    "    return A_gpu.copy_to_host()\n",
    "\n",
    "def dsigmoid_gpu(Z):\n",
    "    \"\"\"\n",
    "    GPU: derivative of sigmoid w.r.t. Z\n",
    "    Returns array of the same shape\n",
    "    \"\"\"\n",
    "    Z_gpu = cuda.to_device(Z)\n",
    "    out = np.empty_like(Z)\n",
    "    out_gpu = cuda.device_array_like(out)\n",
    "    block = (16,16)\n",
    "    grid = grid_2d(Z.shape, block)\n",
    "    dsigmoid_kernel[grid, block](Z_gpu, out_gpu)\n",
    "    out_gpu.copy_to_host(out)\n",
    "    return out\n",
    "\n",
    "def transpose_gpu(A):\n",
    "    \"\"\"\n",
    "    GPU: T = A^T\n",
    "    \"\"\"\n",
    "    T = np.empty((A.shape[1], A.shape[0]), dtype=A.dtype)\n",
    "    A_gpu = cuda.to_device(A)\n",
    "    T_gpu = cuda.device_array_like(T)\n",
    "    block = (16,16)\n",
    "    grid = grid_2d(A.shape, block)\n",
    "    transpose_kernel[grid, block](A_gpu, T_gpu)\n",
    "    T_gpu.copy_to_host(T)\n",
    "    return T\n",
    "\n",
    "def sum_columns_gpu(A):\n",
    "    \"\"\"\n",
    "    GPU: return sum of each row in A, result shape (A.shape[0], 1)\n",
    "    \"\"\"\n",
    "    A_gpu = cuda.to_device(A)\n",
    "    out = np.zeros((A.shape[0], 1), dtype=A.dtype)\n",
    "    out_gpu = cuda.device_array_like(out)\n",
    "    threads = 256\n",
    "    blocks = (A.shape[0] + threads - 1)//threads\n",
    "    sum_columns_kernel[blocks, threads](A_gpu, out_gpu)\n",
    "    out_gpu.copy_to_host(out)\n",
    "    return out\n",
    "\n",
    "def scalar_multiply_gpu(A, scalar):\n",
    "    \"\"\"\n",
    "    GPU: out = A * scalar\n",
    "    \"\"\"\n",
    "    A_gpu = cuda.to_device(A)\n",
    "    out = np.empty_like(A)\n",
    "    out_gpu = cuda.device_array_like(out)\n",
    "    block = (16,16)\n",
    "    grid = grid_2d(A.shape, block)\n",
    "    scalar_mul_kernel[grid, block](A_gpu, scalar, out_gpu)\n",
    "    out_gpu.copy_to_host(out)\n",
    "    return out\n",
    "\n",
    "def add_bias_gpu(A, bias):\n",
    "    \"\"\"\n",
    "    GPU: Out = A + bias (broadcast across columns)\n",
    "    A.shape = (m, n), bias.shape = (m,1)\n",
    "    \"\"\"\n",
    "    A_gpu = cuda.to_device(A)\n",
    "    B_gpu = cuda.to_device(bias)\n",
    "    out = np.empty_like(A)\n",
    "    out_gpu = cuda.device_array_like(out)\n",
    "    block = (16,16)\n",
    "    grid = grid_2d(A.shape, block)\n",
    "    add_bias_kernel[grid, block](A_gpu, B_gpu, out_gpu)\n",
    "    out_gpu.copy_to_host(out)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Small Neural Network (Everything GPU for main ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, n_in, n_out, minibatch_size):\n",
    "        \"\"\"\n",
    "        weights shape = (n_out, n_in)\n",
    "        biases shape = (n_out, 1)\n",
    "        a, z, delta shape = (n_out, minibatch_size)\n",
    "        \"\"\"\n",
    "        self.weights = np.random.normal(0, 1/np.sqrt(n_in), (n_out, n_in))\n",
    "        self.biases  = np.zeros((n_out, 1), dtype=np.float64)\n",
    "\n",
    "        self.z     = np.zeros((n_out, minibatch_size), dtype=np.float64)\n",
    "        self.a     = np.zeros((n_out, minibatch_size), dtype=np.float64)\n",
    "        self.delta = np.zeros((n_out, minibatch_size), dtype=np.float64)\n",
    "\n",
    "class ANN:\n",
    "    def __init__(self, layer_sizes, alpha, minibatch):\n",
    "        \"\"\"\n",
    "        layer_sizes: e.g. [784, 30, 10]\n",
    "        alpha: learning rate\n",
    "        minibatch: batch size\n",
    "        \"\"\"\n",
    "        self.alpha = alpha\n",
    "        self.minibatch = minibatch\n",
    "        self.layers = []\n",
    "        for i in range(len(layer_sizes)-1):\n",
    "            self.layers.append(Layer(layer_sizes[i], layer_sizes[i+1], minibatch))\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        X shape = (n_in, batch_size)\n",
    "        \"\"\"\n",
    "        # input is a(0)\n",
    "        self.layers[0].a = X.copy()\n",
    "\n",
    "        for i in range(len(self.layers)-1):\n",
    "            l_in  = self.layers[i]\n",
    "            l_out = self.layers[i+1]\n",
    "            # z = W * a_in + bias\n",
    "            ztmp = dot_product_gpu(l_out.weights, l_in.a)\n",
    "            ztmp = add_bias_gpu(ztmp, l_out.biases)  # GPU broadcast add\n",
    "            l_out.z = ztmp\n",
    "            l_out.a = sigmoid_gpu(ztmp)  # GPU in-place sigmoid\n",
    "\n",
    "        return self.layers[-1].a\n",
    "\n",
    "    def backward(self, X, Y):\n",
    "        \"\"\"\n",
    "        Y shape = (n_out, batch_size)\n",
    "        \"\"\"\n",
    "        L = len(self.layers) - 1\n",
    "        out_layer = self.layers[L]\n",
    "\n",
    "        # delta_L = (a_L - Y) * dsigmoid(Z_L)\n",
    "        diff = subtract_gpu(out_layer.a, Y)\n",
    "        dsgm = dsigmoid_gpu(out_layer.z)\n",
    "        out_layer.delta = hadamard_gpu(diff, dsgm)\n",
    "\n",
    "        # propagate deltas backward\n",
    "        for i in reversed(range(1, L)):\n",
    "            curr = self.layers[i]     \n",
    "            nxt  = self.layers[i+1]   \n",
    "            wT = transpose_gpu(nxt.weights)\n",
    "            dprop = dot_product_gpu(wT, nxt.delta)\n",
    "            dsgm_i = dsigmoid_gpu(curr.z)\n",
    "            curr.delta = hadamard_gpu(dprop, dsgm_i)\n",
    "\n",
    "        # weight/bias updates\n",
    "        for i in range(1, len(self.layers)):\n",
    "            prev = self.layers[i-1]\n",
    "            curr = self.layers[i]\n",
    "\n",
    "            # dW = (delta_i @ a_{i-1}^T) * (alpha / batch_size)\n",
    "            aT = transpose_gpu(prev.a)\n",
    "            dW = dot_product_gpu(curr.delta, aT)\n",
    "            scale = self.alpha / self.minibatch\n",
    "            dW_scaled = scalar_multiply_gpu(dW, scale)\n",
    "            curr.weights = subtract_gpu(curr.weights, dW_scaled)\n",
    "\n",
    "            # dB = sum of delta_i across columns, then scale\n",
    "            sumd = sum_columns_gpu(curr.delta)  # shape (n_out, 1)\n",
    "            sumd_scaled = scalar_multiply_gpu(sumd, scale)\n",
    "            curr.biases = subtract_gpu(curr.biases, sumd_scaled)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # forward pass\n",
    "        out = self.forward(X)\n",
    "        # for classification, do CPU argmax\n",
    "        return np.argmax(out, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Training / Testing with MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(labels, n_classes=10):\n",
    "    arr = np.zeros((n_classes, len(labels)), dtype=np.float64)\n",
    "    arr[labels, np.arange(len(labels))] = 1.0\n",
    "    return arr\n",
    "\n",
    "def accuracy(model, X, Y):\n",
    "    \"\"\"\n",
    "    Evaluate classification accuracy\n",
    "    X shape: (n_in, num_samples)\n",
    "    Y shape: (num_samples,) with integer labels\n",
    "    \"\"\"\n",
    "    batch_size = model.minibatch\n",
    "    num_samples = X.shape[1]\n",
    "    nbatches = (num_samples // batch_size)*batch_size\n",
    "    correct = 0\n",
    "    for i in range(0, nbatches, batch_size):\n",
    "        xb = X[:, i:i+batch_size]\n",
    "        yb = Y[i:i+batch_size]\n",
    "        preds = model.predict(xb)\n",
    "        correct += np.sum(preds == yb)\n",
    "    return correct / nbatches\n",
    "\n",
    "def cross_entropy_cpu(predictions, targets):\n",
    "    \"\"\"\n",
    "    CPU cross-entropy\n",
    "    predictions, targets shape: (n_out, batch_size)\n",
    "    \"\"\"\n",
    "    eps = 1e-12\n",
    "    clipped = np.clip(predictions, eps, 1-eps)\n",
    "    return -np.sum(targets * np.log(clipped)) / predictions.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sacha\\miniconda3\\envs\\ECN_GPU\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "c:\\Users\\sacha\\miniconda3\\envs\\ECN_GPU\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "c:\\Users\\sacha\\miniconda3\\envs\\ECN_GPU\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Accuracy: 9.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sacha\\miniconda3\\envs\\ECN_GPU\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "c:\\Users\\sacha\\miniconda3\\envs\\ECN_GPU\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "c:\\Users\\sacha\\miniconda3\\envs\\ECN_GPU\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "c:\\Users\\sacha\\miniconda3\\envs\\ECN_GPU\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 49 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "c:\\Users\\sacha\\miniconda3\\envs\\ECN_GPU\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 49 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "c:\\Users\\sacha\\miniconda3\\envs\\ECN_GPU\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "c:\\Users\\sacha\\miniconda3\\envs\\ECN_GPU\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "c:\\Users\\sacha\\miniconda3\\envs\\ECN_GPU\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single-epoch training time: 47.8031 s\n",
      "Memory transfer time: 32.6426 s\n",
      "Fraction of time spent in memory transfers: 68.29%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Basic config\n",
    "    DATA_PATH = \"DATA\"\n",
    "    train_img = read_images(os.path.join(DATA_PATH, \"train-images.idx3-ubyte\"))\n",
    "    train_label = read_labels(os.path.join(DATA_PATH, \"train-labels.idx1-ubyte\"))\n",
    "    test_img  = read_images(os.path.join(DATA_PATH, \"t10k-images.idx3-ubyte\"))\n",
    "    test_label = read_labels(os.path.join(DATA_PATH, \"t10k-labels.idx1-ubyte\"))\n",
    "\n",
    "    # Normalize to [0,1]\n",
    "    train_img = train_img.astype(np.float64) / 255.0\n",
    "    test_img  = test_img.astype(np.float64)  / 255.0\n",
    "\n",
    "    # Hyperparameters\n",
    "    alpha = 0.05\n",
    "    batch_size = 16\n",
    "    layer_sizes = [784, 30, 10]\n",
    "    epochs = 5\n",
    "\n",
    "    # Build net\n",
    "    net = ANN(layer_sizes, alpha, batch_size)\n",
    "\n",
    "    Xtest = test_img.T \n",
    "    Ytest = test_label\n",
    "\n",
    "    init_acc = accuracy(net, Xtest, Ytest)\n",
    "    print(f\"Initial Accuracy: {init_acc*100:.2f}%\")\n",
    "\n",
    "    N = train_img.shape[0]\n",
    "    for ep in range(epochs):\n",
    "        idx = np.arange(N)\n",
    "        np.random.shuffle(idx)\n",
    "        ce_total = 0.0\n",
    "        n_batches = 0\n",
    "\n",
    "        for i in tqdm(range(0, N - batch_size + 1, batch_size)):\n",
    "            bidx = idx[i:i+batch_size]\n",
    "            x_b  = train_img[bidx].T  # shape (784, batch_size)\n",
    "            y_b  = one_hot(train_label[bidx], 10)\n",
    "\n",
    "            # Forward\n",
    "            out = net.forward(x_b)\n",
    "            # Cross-entropy on CPU\n",
    "            ce = cross_entropy_cpu(out, y_b)\n",
    "            ce_total += ce\n",
    "\n",
    "            # Backward\n",
    "            net.backward(x_b, y_b)\n",
    "            n_batches += 1\n",
    "\n",
    "        acc_val = accuracy(net, Xtest, Ytest)\n",
    "        print(f\"Epoch {ep+1}, Accuracy: {acc_val*100:.2f}%, CE: {ce_total/n_batches:.4f}\")\n",
    "\n",
    "    final_acc = accuracy(net, Xtest, Ytest)\n",
    "    print(f\"Final Test Accuracy on 1000 samples: {final_acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tester le temps de memoire (ATTENTION, pour que ça marche, il faut enlever le training loop dans la cellule précédente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Single-Epoch Training & Memory Transfer Timing (Patch-Free)\n",
    "\n",
    "# %%\n",
    "import time\n",
    "\n",
    "# Global accumulator for CPU↔GPU transfer times\n",
    "mem_transfer_time = 0.0\n",
    "\n",
    "def to_device_timed(arr):\n",
    "    \"\"\"Send arr to device, accumulate time in mem_transfer_time.\"\"\"\n",
    "    global mem_transfer_time\n",
    "    start = time.time()\n",
    "    d_arr = cuda.to_device(arr)\n",
    "    mem_transfer_time += (time.time() - start)\n",
    "    return d_arr\n",
    "\n",
    "def copy_to_host_timed(device_arr, host_arr=None):\n",
    "    \"\"\"Copy from device to host, accumulate time in mem_transfer_time.\"\"\"\n",
    "    global mem_transfer_time\n",
    "    start = time.time()\n",
    "    res = device_arr.copy_to_host(host_arr)\n",
    "    mem_transfer_time += (time.time() - start)\n",
    "    return res\n",
    "\n",
    "# Now redefine the GPU helper functions, but use the timed transfer calls:\n",
    "def dot_product_gpu(A, B):\n",
    "    global mem_transfer_time\n",
    "    A_gpu = to_device_timed(A)\n",
    "    B_gpu = to_device_timed(B)\n",
    "    C = np.empty((A.shape[0], B.shape[1]), dtype=np.float64)\n",
    "    C_gpu = cuda.device_array_like(C)\n",
    "    block = (16, 16)\n",
    "    grid = grid_2d(C.shape, block)\n",
    "    dot_product_kernel[grid, block](A_gpu, B_gpu, C_gpu)\n",
    "    copy_to_host_timed(C_gpu, C)\n",
    "    return C\n",
    "\n",
    "def hadamard_gpu(A, B):\n",
    "    A_gpu = to_device_timed(A)\n",
    "    B_gpu = to_device_timed(B)\n",
    "    out = np.empty_like(A)\n",
    "    out_gpu = cuda.device_array_like(out)\n",
    "    block = (16,16)\n",
    "    grid = grid_2d(A.shape, block)\n",
    "    hadamard_kernel[grid, block](A_gpu, B_gpu, out_gpu)\n",
    "    copy_to_host_timed(out_gpu, out)\n",
    "    return out\n",
    "\n",
    "def subtract_gpu(A, B):\n",
    "    A_gpu = to_device_timed(A)\n",
    "    B_gpu = to_device_timed(B)\n",
    "    out = np.empty_like(A)\n",
    "    out_gpu = cuda.device_array_like(out)\n",
    "    block = (16,16)\n",
    "    grid = grid_2d(A.shape, block)\n",
    "    subtract_kernel[grid, block](A_gpu, B_gpu, out_gpu)\n",
    "    copy_to_host_timed(out_gpu, out)\n",
    "    return out\n",
    "\n",
    "def sigmoid_gpu(A):\n",
    "    A_gpu = to_device_timed(A)\n",
    "    block = (16,16)\n",
    "    grid = grid_2d(A.shape, block)\n",
    "    sigmoid_kernel[grid, block](A_gpu)\n",
    "    return copy_to_host_timed(A_gpu)\n",
    "\n",
    "def dsigmoid_gpu(Z):\n",
    "    Z_gpu = to_device_timed(Z)\n",
    "    out = np.empty_like(Z)\n",
    "    out_gpu = cuda.device_array_like(out)\n",
    "    block = (16,16)\n",
    "    grid = grid_2d(Z.shape, block)\n",
    "    dsigmoid_kernel[grid, block](Z_gpu, out_gpu)\n",
    "    copy_to_host_timed(out_gpu, out)\n",
    "    return out\n",
    "\n",
    "def transpose_gpu(A):\n",
    "    T = np.empty((A.shape[1], A.shape[0]), dtype=A.dtype)\n",
    "    A_gpu = to_device_timed(A)\n",
    "    T_gpu = cuda.device_array_like(T)\n",
    "    block = (16,16)\n",
    "    grid = grid_2d(A.shape, block)\n",
    "    transpose_kernel[grid, block](A_gpu, T_gpu)\n",
    "    copy_to_host_timed(T_gpu, T)\n",
    "    return T\n",
    "\n",
    "def sum_columns_gpu(A):\n",
    "    A_gpu = to_device_timed(A)\n",
    "    out = np.zeros((A.shape[0], 1), dtype=A.dtype)\n",
    "    out_gpu = cuda.device_array_like(out)\n",
    "    threads = 256\n",
    "    blocks = (A.shape[0] + threads - 1)//threads\n",
    "    sum_columns_kernel[blocks, threads](A_gpu, out_gpu)\n",
    "    copy_to_host_timed(out_gpu, out)\n",
    "    return out\n",
    "\n",
    "def scalar_multiply_gpu(A, scalar):\n",
    "    A_gpu = to_device_timed(A)\n",
    "    out = np.empty_like(A)\n",
    "    out_gpu = cuda.device_array_like(out)\n",
    "    block = (16,16)\n",
    "    grid = grid_2d(A.shape, block)\n",
    "    scalar_mul_kernel[grid, block](A_gpu, scalar, out_gpu)\n",
    "    copy_to_host_timed(out_gpu, out)\n",
    "    return out\n",
    "\n",
    "def add_bias_gpu(A, bias):\n",
    "    A_gpu = to_device_timed(A)\n",
    "    B_gpu = to_device_timed(bias)\n",
    "    out = np.empty_like(A)\n",
    "    out_gpu = cuda.device_array_like(out)\n",
    "    block = (16,16)\n",
    "    grid = grid_2d(A.shape, block)\n",
    "    add_bias_kernel[grid, block](A_gpu, B_gpu, out_gpu)\n",
    "    copy_to_host_timed(out_gpu, out)\n",
    "    return out\n",
    "\n",
    "###############################################################################\n",
    "# 2) Single-epoch training to measure total time vs. memory copy time\n",
    "###############################################################################\n",
    "start_time = time.time()\n",
    "\n",
    "# Create or reuse a net\n",
    "single_epoch_net = ANN(layer_sizes, alpha, batch_size)\n",
    "\n",
    "N_train = train_img.shape[0]\n",
    "indices = np.arange(N_train)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "ce_total = 0.0\n",
    "n_batches = 0\n",
    "\n",
    "for i in range(0, N_train - batch_size + 1, batch_size):\n",
    "    batch_idx = indices[i : i + batch_size]\n",
    "    x_b = train_img[batch_idx].T\n",
    "    y_b = one_hot(train_label[batch_idx], 10)\n",
    "\n",
    "    # Forward\n",
    "    out = single_epoch_net.forward(x_b)\n",
    "\n",
    "    # Cross-entropy on CPU\n",
    "    ce = cross_entropy_cpu(out, y_b)\n",
    "    ce_total += ce\n",
    "\n",
    "    # Backward\n",
    "    single_epoch_net.backward(x_b, y_b)\n",
    "    n_batches += 1\n",
    "\n",
    "end_time = time.time()\n",
    "total_training_time = end_time - start_time\n",
    "\n",
    "###############################################################################\n",
    "# 3) Print results\n",
    "###############################################################################\n",
    "print(f\"Single-epoch training time: {total_training_time:.4f} s\")\n",
    "print(f\"Memory transfer time: {mem_transfer_time:.4f} s\")\n",
    "if total_training_time > 0:\n",
    "    frac = 100.0 * mem_transfer_time / total_training_time\n",
    "    print(f\"Fraction of time spent in memory transfers: {frac:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time for 1 epoch :   47.8031 seconds\n",
      "Memory-transfer time :     32.6426 seconds\n",
      "Share of time in memcopy : 68.29%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total time for 1 epoch :   {total_training_time:.4f} seconds\")\n",
    "print(f\"Memory-transfer time :     {mem_transfer_time:.4f} seconds\")\n",
    "print(f\"Share of time in memcopy : {(mem_transfer_time / total_training_time) * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ECN_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
